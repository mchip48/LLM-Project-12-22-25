import os
from dotenv import load_dotenv
from pinecone import Pinecone
import re # regular expression - regex

load_dotenv()

def split_markdown_by_h2(md_text):
  """Converts Markdown file into a list of text chunks. Each chunk spans one section of the text, defined by H2s"""
  # regex - pattern is from H2 to next H2 or EOF
  pattern = r"(?m)^## .+?(?=^## |\Z)"

  chunks = re.findall(pattern, md_text, re.DOTALL)
  return [chunk.strip() for chunk in chunks if chunk.strip()]

# Grab the documentation from the flamehamster docs
with open("flamehamster.md", "r", encoding="utf-8") as file:
  documentation = file.read()

# pass in the documentation into the split_markdown_by_h2 function to split it into relevant chunks
chunks = split_markdown_by_h2(documentation)

# wrap each chunk in the record format that Pinecone expects:
records = []
for i, chunk in enumerate(chunks):
  records.append({
    "id": f"chunk-{i}",
    "chunk_text": chunk,
    "manual": "flamehamster"
  })

# upload/upsert the chunks into the Pinecone index/database
pc = Pinecone(api_key=os.getenv("PINECONE_API_KEY"))
dense_index = pc.Index("llm-project-1")
# dense_index.upsert_records("flamehamster", records)

BATCH_SIZE = 96
for i in range(0, len(records), BATCH_SIZE):
   batch = records[i:i + BATCH_SIZE]
   dense_index.upsert_records("flamehamster", batch)
   print(f"Upserted batch {i // BATCH_SIZE + 1} ({len(batch)} records)")


print(f"Done! Uploaded {len(records)} chunks to Pinecone.")

# Postgres - PGVector
# HuggingsFace Embeddings
# OpenAI Embeddings API  